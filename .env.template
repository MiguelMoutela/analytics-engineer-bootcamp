# port these into a .env file and add credentials
PYTHONFAULTHANDLER=false

AIRFLOW__SECRETS__BACKEND=airflow.providers.amazon.aws.secrets.secrets_manager.SecretsManagerBackend
AIRFLOW__SECRETS__BACKEND_KWARGS={"connections_prefix": "airflow/connections", "variables_prefix": "airflow/variables"}
AIRFLOW_CONN_AWS_DEFAULT=aws://

DATAEXPERT_AWS_ACCESS_KEY_ID=
DATAEXPERT_AWS_SECRET_ACCESS_KEY=
DATAEXPERT_AWS_REGION=
DATAEXPERT_AWS_DEFAULT_REGION=
DATAEXPERT_S3_BUCKET_TABULAR=
DATAEXPERT_POLYGON_API_KEY=

DATAEXPERT_TRINO_HOST=
DATAEXPERT_TRINO_CATALOG=
DATAEXPERT_TRINO_USER=
DATAEXPERT_TRINO_PW=
DATAEXPERT_DAG_OWNER=

SCHEMA=
STUDENT_SCHEMA=
DBT_PROFILES_DIR=.
DBT_PROJECT_DIR=.
DBT_PARTIAL_PARSE=False

PG_HOST=
PG_DATABASE=
PG_PORT=
PG_USER=
PG_PASSWORD=

SF_ACCOUNT=
SF_USER=
SF_ROLE=
SF_WAREHOUSE=
SF_DATABASE=
SF_SCHEMA=
SF_PRIVATE_KEY_PATH=
SF_PRIVATE_KEY_PASSPHRASE=
